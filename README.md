# Optimizing Workforce Performance: An End-to-End HR Analytics Pipeline

## Repository Outline
```
- README(description).md | Overview of the project description.
- P2M3_Yonathan_Anggraiwan_GX.ipynb | This notebook containing the codes and explanation of the data expectations and validations processing steps using Great Expectations.
- P2M3_Yonathan_Anggraiwan_conceptual.txt | This 
- P2M3_Yonathan_Anggraiwan_DAG.py | This python file containing the codes of the end to end data pipeline that being used in this project, which is the data is being loaded from PostgreSQL, then being visualized by Kibana in Elasticsearch.
- P2M3_Yonathan_Anggraiwan_conceptual.txt | A text file explaining conceptual problems, including the explanations of NoSQL, RDBMS, tools from NoSQL, Airflow explanations, Great Expectations explanations, and Batch Processing explanations.
- P2M3_Yonathan_Anggraiwan_ddl.txt | A text file that containing the sql from creating data base, creating data table and loading data table that being used in this project.
- P2M3_Yonathan_Anggraiwan_dataset_data_raw.csv | Raw CSV dataset.
- P2M3_Yonathan_Anggraiwan_dataset_data_clean.csv | Clean CSV dataset used for data analysis and visualize data.
- Images folder | Folder that containing all of the visualize data that being used on the dashboard.
```

## Problem Background
`I am a data analyst working in a big company. On this occasion, the HR team has asked me to analyze the Employee Performance and Productivity dataset to extract actionable insights that support strategic decision making.`

## Project Output
`The output of my project this time is present the result of data Great Expecations and data visualization using kibana on Elasticsearch.`

## Data
`The dataset used in this project comes from Kaggle (). It contains customer financial informations, with 100,000 rows and 20 columns. The dataset is considered clean, with no duplicate entries or missing values.`

## Method
`In this moment, I am building an end-to-end data pipeline using Apache Airflow, Docker, PostgreSQL, and Elasticsearch. Iâ€™ve also implemented data validation steps using Great Expectations to ensure data integrity throughout the workflow. The final output is visualized in Kibana to provide the HR team with clear and interactive dashboards.`

## Stacks
`The programming language used in this project is Python, with VSCode as the development tool. The libraries used include pandas, and Great Expectations. Data visualization is also presented in kibana dashboard.`

## Reference
`The supporting link for the results of this project analysis can be found in the following project dashboard link:
https://huggingface.co/spaces/rvpishere/Risk_Score_Prediction_In_Bank_Loan_Application`

---

**Additional Information:**
Contact Person:
- [E-mail](yonathan.anggraiwan.work@gmail.com)
